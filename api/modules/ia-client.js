// ================================================================================
// ü§ñ IA-CLIENT.JS - CLIENTE DE IA (OPENAI + CLAUDE)
// ================================================================================
// Respons√°vel por: Chamadas para OpenAI, Claude, fallbacks, sele√ß√£o de modelo
// ================================================================================

import { MAX_TOKENS } from './config.js';

// ================================================================================
// üéØ FUN√á√ÉO PRINCIPAL: CHAMAR IA COM SEGURAN√áA
// ================================================================================

export async function chamarIASegura(prompt, temImagem, arquivo, modelo, fallbackModelo) {
  console.log('[IA-CLIENT] Iniciando chamada segura...', { modelo, temImagem });
  
  try {
    if (temImagem === true) {
      console.log('[IA-CLIENT] Chamando Claude para an√°lise de imagem...');
      return await chamarClaude(prompt, arquivo, modelo);
    } else {
      console.log('[IA-CLIENT] Chamando OpenAI para processamento de texto...');
      return await chamarOpenAI(prompt, false, null, modelo);
    }
  } catch (erro1) {
    console.error(`‚ùå [IA-CLIENT] Falha no modelo principal ${modelo}:`, erro1.message);
    
    // ================================================================================
    // üîÑ SISTEMA DE FALLBACK INTELIGENTE
    // ================================================================================
    
    if (temImagem === true) {
      console.warn(`‚ö†Ô∏è [IA-CLIENT] Claude falhou, tentando GPT-4o com vis√£o...`);
      try {
        return await chamarOpenAI(prompt, true, arquivo, 'gpt-4o');
      } catch (erro2) {
        console.error(`‚ùå [IA-CLIENT] GPT-4o tamb√©m falhou:`, erro2.message);
        throw new Error(`Ambos os modelos de imagem falharam: Claude (${erro1.message}) | GPT-4o (${erro2.message})`);
      }
    } else {
      console.warn(`‚ö†Ô∏è [IA-CLIENT] Tentando fallback com ${fallbackModelo}...`);
      try {
        return await chamarOpenAI(prompt, false, null, fallbackModelo);
      } catch (erro2) {
        console.error(`‚ùå [IA-CLIENT] Fallback tamb√©m falhou:`, erro2.message);
        throw new Error(`Ambos os modelos de texto falharam: ${modelo} (${erro1.message}) | ${fallbackModelo} (${erro2.message})`);
      }
    }
  }
}

// ================================================================================
// üß† FUN√á√ÉO: CHAMAR CLAUDE (ANTHROPIC)
// ================================================================================

async function chamarClaude(prompt, arquivo, modelo) {
  console.log('[IA-CLIENT] Preparando chamada para Claude...');
  
  if (!process.env.ANTHROPIC_API_KEY) {
    throw new Error('ANTHROPIC_API_KEY n√£o encontrada nas vari√°veis de ambiente');
  }

  const base64Match = arquivo.match(/data:(image\/[^;]+);base64,(.+)/);
  if (!base64Match) {
    throw new Error('Formato de imagem base64 inv√°lido para Claude');
  }

  const content = [
    { type: "text", text: prompt },
    { type: "image", source: { type: "base64", media_type: base64Match[1], data: base64Match[2] } }
  ];

  console.log('[IA-CLIENT] Enviando requisi√ß√£o para Claude...');

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'x-api-key': process.env.ANTHROPIC_API_KEY,
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model: modelo,
      max_tokens: MAX_TOKENS,
      messages: [{ role: 'user', content }]
    })
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Erro na API Claude ${response.status}: ${errorText.substring(0, 200)}`);
  }

  const data = await response.json();
  if (!data.content?.[0]?.text) {
    throw new Error('Resposta da API Claude em formato inv√°lido');
  }

  console.log('[IA-CLIENT] ‚úÖ Claude respondeu com sucesso');

  return {
    content: data.content[0].text,
    usage: data.usage || { input_tokens: 0, output_tokens: 0 },
    modelo_usado: modelo
  };
}

// ================================================================================
// ü§ñ FUN√á√ÉO: CHAMAR OPENAI (GPT)
// ================================================================================

async function chamarOpenAI(prompt, temImagem, arquivo, modelo) {
  console.log('[IA-CLIENT] Preparando chamada para OpenAI...', { modelo, temImagem });
  
  if (!process.env.OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY n√£o encontrada nas vari√°veis de ambiente');
  }

  let messages;
  if (temImagem === true && arquivo) {
    console.log('[IA-CLIENT] Configurando OpenAI para an√°lise de imagem...');
    messages = [
      {
        role: "user",
        content: [
          { type: "text", text: prompt },
          { type: "image_url", image_url: { url: arquivo } }
        ]
      }
    ];
  } else {
    console.log('[IA-CLIENT] Configurando OpenAI para processamento de texto...');
    messages = [{ role: "user", content: prompt }];
  }

  console.log('[IA-CLIENT] Enviando requisi√ß√£o para OpenAI...');

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: modelo,
      messages: messages,
      max_tokens: MAX_TOKENS,
      temperature: 0.1
    })
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Erro na API OpenAI ${response.status}: ${errorText.substring(0, 200)}`);
  }

  const data = await response.json();
  if (!data.choices?.[0]?.message?.content) {
    throw new Error('Resposta da API OpenAI em formato inv√°lido');
  }

  console.log('[IA-CLIENT] ‚úÖ OpenAI respondeu com sucesso');

  return {
    content: data.choices[0].message.content,
    usage: data.usage || { prompt_tokens: 0, completion_tokens: 0 },
    modelo_usado: modelo
  };
}

// ================================================================================
// üéØ FUN√á√ÉO: SELE√á√ÉO INTELIGENTE DE MODELO
// ================================================================================

export function selecionarModelo(temImagem) {
  if (temImagem === true) {
    return {
      modelo: 'claude-3-5-sonnet-20240620',
      estrategia: 'Claude para an√°lise visual',
      fallback: 'gpt-4o'
    };
  } else {
    return {
      modelo: 'gpt-4o-mini',
      estrategia: 'GPT-4o-mini para texto',
      fallback: 'gpt-4o'
    };
  }
}

// ================================================================================
// üîß FUN√á√ÉO: VERIFICAR DISPONIBILIDADE DAS APIs
// ================================================================================

export function verificarDisponibilidadeAPIs() {
  const status = {
    openai: !!process.env.OPENAI_API_KEY,
    anthropic: !!process.env.ANTHROPIC_API_KEY
  };
  
  console.log('[IA-CLIENT] Status das APIs:', status);
  
  return status;
}

// ================================================================================
// üéØ FUN√á√ÉO: TESTE DE CONECTIVIDADE
// ================================================================================

export async function testarConectividade() {
  const resultados = {
    openai: false,
    anthropic: false,
    erros: []
  };
  
  // Testar OpenAI
  if (process.env.OPENAI_API_KEY) {
    try {
      await chamarOpenAI('Teste de conectividade. Responda apenas: OK', false, null, 'gpt-4o-mini');
      resultados.openai = true;
      console.log('[IA-CLIENT] ‚úÖ OpenAI conectada');
    } catch (error) {
      resultados.erros.push(`OpenAI: ${error.message}`);
      console.log('[IA-CLIENT] ‚ùå OpenAI falhou');
    }
  }
  
  // Testar Anthropic (s√≥ se necess√°rio)
  if (process.env.ANTHROPIC_API_KEY) {
    console.log('[IA-CLIENT] ‚úÖ Anthropic configurada (n√£o testando conectividade)');
    resultados.anthropic = true;
  }
  
  return resultados;
}

// ================================================================================
// üîß FUN√á√ÉO: OBTER INFORMA√á√ïES DE USO
// ================================================================================

export function obterInformacoesUso(resultado) {
  const usage = resultado.usage || {};
  
  return {
    modelo: resultado.modelo_usado || 'desconhecido',
    tokens_input: usage.input_tokens || usage.prompt_tokens || 0,
    tokens_output: usage.output_tokens || usage.completion_tokens || 0,
    tokens_total: (usage.input_tokens || usage.prompt_tokens || 0) + 
                  (usage.output_tokens || usage.completion_tokens || 0)
  };
}

console.log('‚úÖ [IA-CLIENT] M√≥dulo de cliente IA carregado');
console.log('ü§ñ [IA-CLIENT] Suporte: OpenAI (texto/imagem) + Claude (imagem)');